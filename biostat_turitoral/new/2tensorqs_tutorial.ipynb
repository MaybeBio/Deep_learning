{"cells":[{"cell_type":"markdown","metadata":{"id":"kTf8QtYlkVgY"},"source":["[Learn the Basics](intro.html) \\|\\|\n","[Quickstart](quickstart_tutorial.html) \\|\\| **Tensors** \\|\\| [Datasets &\n","DataLoaders](data_tutorial.html) \\|\\|\n","[Transforms](transforms_tutorial.html) \\|\\| [Build\n","Model](buildmodel_tutorial.html) \\|\\|\n","[Autograd](autogradqs_tutorial.html) \\|\\|\n","[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n","Model](saveloadrun_tutorial.html)\n","\n","Tensors\n","=======\n","\n","Tensors are a specialized data structure that are very similar to arrays\n","and matrices. In PyTorch, we use tensors to encode the inputs and\n","outputs of a model, as well as the model's parameters.\n","\n","Tensors are similar to [NumPy's](https://numpy.org/) ndarrays, except\n","that tensors can run on GPUs or other hardware accelerators. In fact,\n","tensors and NumPy arrays can often share the same underlying memory,\n","eliminating the need to copy data (see\n","`bridge-to-np-label`{.interpreted-text role=\"ref\"}). Tensors are also\n","optimized for automatic differentiation (we\\'ll see more about that\n","later in the [Autograd](autogradqs_tutorial.html) section). If you're\n","familiar with ndarrays, you'll be right at home with the Tensor API. If\n","not, follow along!\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ulHFkW9jkVga"},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"eqxfMCVgkVgb"},"source":["Initializing a Tensor\n","=====================\n","\n","Tensors can be initialized in various ways. Take a look at the following\n","examples:\n","\n","**Directly from data**\n","\n","Tensors can be created directly from data. The data type is\n","automatically inferred.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8GCMY4ykVgb","executionInfo":{"status":"ok","timestamp":1746534684352,"user_tz":-480,"elapsed":44,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"9b77093f-cac6-4ef3-eca6-2cc07e1ac26e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":3}],"source":["data = [[1, 2],[3, 4]]\n","x_data = torch.tensor(data)\n","x_data"]},{"cell_type":"markdown","metadata":{"id":"sDv3YU2TkVgb"},"source":["**From a NumPy array**\n","\n","Tensors can be created from NumPy arrays (and vice versa - see\n","`bridge-to-np-label`{.interpreted-text role=\"ref\"}).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqNV47YckVgc"},"outputs":[],"source":["np_array = np.array(data)\n","x_np = torch.from_numpy(np_array)"]},{"cell_type":"markdown","metadata":{"id":"pfqYVde8kVgc"},"source":["**From another tensor:**\n","\n","The new tensor retains the properties (shape, datatype) of the argument\n","tensor, unless explicitly overridden.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TeYD-xKskVgd","executionInfo":{"status":"ok","timestamp":1746534715173,"user_tz":-480,"elapsed":98,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"07e44506-8783-4718-94ac-631ef0059954"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ones Tensor: \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n","Random Tensor: \n"," tensor([[0.7934, 0.9640],\n","        [0.3666, 0.9593]]) \n","\n"]}],"source":["x_ones = torch.ones_like(x_data) # retains the properties of x_data\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","\n","x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n","print(f\"Random Tensor: \\n {x_rand} \\n\")"]},{"cell_type":"markdown","metadata":{"id":"ZoIpoIfBkVgd"},"source":["**With random or constant values:**\n","\n","`shape` is a tuple of tensor dimensions. In the functions below, it\n","determines the dimensionality of the output tensor.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AteAFh6kVge","executionInfo":{"status":"ok","timestamp":1746534765749,"user_tz":-480,"elapsed":14,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"ac4a95e0-6215-48fa-9880-ad68e37637ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Random Tensor: \n"," tensor([[0.9373, 0.1760, 0.5260],\n","        [0.3945, 0.0385, 0.5790]]) \n","\n","Ones Tensor: \n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.]]) \n","\n","Zeros Tensor: \n"," tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"]}],"source":["shape = (2,3,)\n","rand_tensor = torch.rand(shape)\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","\n","print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor}\")"]},{"cell_type":"markdown","metadata":{"id":"qAlW5vL8kVge"},"source":["------------------------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"vjONJluUkVge"},"source":["Attributes of a Tensor\n","======================\n","\n","Tensor attributes describe their shape, datatype, and the device on\n","which they are stored.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2rXuTk7ykVge","executionInfo":{"status":"ok","timestamp":1746534836406,"user_tz":-480,"elapsed":25,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"19e9d3b8-ca0b-4cec-e6eb-8af246e18352"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}],"source":["tensor = torch.rand(3,4)\n","\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"]},{"cell_type":"markdown","metadata":{"id":"Y33VvNe4kVge"},"source":["------------------------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"vY7oYh4-kVge"},"source":["Operations on Tensors\n","=====================\n","\n","Over 1200 tensor operations, including arithmetic, linear algebra,\n","matrix manipulation (transposing, indexing, slicing), sampling and more\n","are comprehensively described\n","[here](https://pytorch.org/docs/stable/torch.html).\n","\n","Each of these operations can be run on the CPU and\n","[Accelerator](https://pytorch.org/docs/stable/torch.html#accelerators)\n","such as CUDA, MPS, MTIA, or XPU. If you're using Colab, allocate an\n","accelerator by going to Runtime \\> Change runtime type \\> GPU.\n","\n","By default, tensors are created on the CPU. We need to explicitly move\n","tensors to the accelerator using `.to` method (after checking for\n","accelerator availability). Keep in mind that copying large tensors\n","across devices can be expensive in terms of time and memory!\n"]},{"cell_type":"code","source":["torch.accelerator.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2svROIYTpTqO","executionInfo":{"status":"ok","timestamp":1746535793441,"user_tz":-480,"elapsed":12,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"546afa88-cef2-4f69-a8e4-dc0e0eac4617"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hPp_ZG6okVgf"},"outputs":[],"source":["# We move our tensor to the current accelerator if available\n","if torch.accelerator.is_available():\n","    tensor = tensor.to(torch.accelerator.current_accelerator())"]},{"cell_type":"markdown","metadata":{"id":"Bm-tCumFkVgf"},"source":["Try out some of the operations from the list. If you\\'re familiar with\n","the NumPy API, you\\'ll find the Tensor API a breeze to use.\n"]},{"cell_type":"markdown","metadata":{"id":"BJ_AnGxBkVgf"},"source":["**Standard numpy-like indexing and slicing:**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W3ggkp-skVgf","executionInfo":{"status":"ok","timestamp":1746535819452,"user_tz":-480,"elapsed":34,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"b6b727e4-1bc2-4ec7-975d-42bb77bc082b"},"outputs":[{"output_type":"stream","name":"stdout","text":["First row: tensor([1., 1., 1., 1.])\n","First column: tensor([1., 1., 1., 1.])\n","Last column: tensor([1., 1., 1., 1.])\n","tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}],"source":["tensor = torch.ones(4, 4)\n","print(f\"First row: {tensor[0]}\")\n","print(f\"First column: {tensor[:, 0]}\")\n","print(f\"Last column: {tensor[..., -1]}\")\n","tensor[:,1] = 0\n","print(tensor)"]},{"cell_type":"markdown","metadata":{"id":"uGEU-SkwkVgf"},"source":["**Joining tensors** You can use `torch.cat` to concatenate a sequence of\n","tensors along a given dimension. See also\n","[torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html),\n","another tensor joining operator that is subtly different from\n","`torch.cat`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZSIeguNAkVgf","executionInfo":{"status":"ok","timestamp":1746535880643,"user_tz":-480,"elapsed":18,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"1bc93c11-63e6-4d06-ff69-6ac94347d6a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"]}],"source":["t1 = torch.cat([tensor, tensor, tensor], dim=1)\n","print(t1)"]},{"cell_type":"markdown","metadata":{"id":"sdl_XJckkVgf"},"source":["**Arithmetic operations**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NP_RFLX-kVgf","executionInfo":{"status":"ok","timestamp":1746535915394,"user_tz":-480,"elapsed":158,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"9c20621c-ab17-4e6f-fb0e-5aae6932ca9c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])"]},"metadata":{},"execution_count":12}],"source":["# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n","# ``tensor.T`` returns the transpose of a tensor\n","y1 = tensor @ tensor.T\n","y2 = tensor.matmul(tensor.T)\n","\n","y3 = torch.rand_like(y1)\n","torch.matmul(tensor, tensor.T, out=y3)\n","\n","\n","# This computes the element-wise product. z1, z2, z3 will have the same value\n","z1 = tensor * tensor\n","z2 = tensor.mul(tensor)\n","\n","z3 = torch.rand_like(tensor)\n","torch.mul(tensor, tensor, out=z3)"]},{"cell_type":"markdown","metadata":{"id":"8bqHddc0kVgg"},"source":["**Single-element tensors** If you have a one-element tensor, for example\n","by aggregating all values of a tensor into one value, you can convert it\n","to a Python numerical value using `item()`:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lsiUf4amkVgg","executionInfo":{"status":"ok","timestamp":1746536029527,"user_tz":-480,"elapsed":4,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"7ca88e99-5aab-4162-8c83-6d21b2043914"},"outputs":[{"output_type":"stream","name":"stdout","text":["12.0 <class 'float'>\n"]}],"source":["agg = tensor.sum()\n","agg_item = agg.item()\n","print(agg_item, type(agg_item))"]},{"cell_type":"markdown","metadata":{"id":"IZmVZR0zkVgg"},"source":["**In-place operations** Operations that store the result into the\n","operand are called in-place. They are denoted by a `_` suffix. For\n","example: `x.copy_(y)`, `x.t_()`, will change `x`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7vPVDdBkVgg","executionInfo":{"status":"ok","timestamp":1746536156701,"user_tz":-480,"elapsed":29,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"258d8482-b1d0-4797-a385-ce7e961c0877"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.]])\n"]}],"source":["print(f\"{tensor} \\n\")\n","tensor.add_(5)\n","print(tensor)"]},{"cell_type":"markdown","metadata":{"id":"9ZzrBuxFkVgg"},"source":["<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n","\n","<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n","\n","<p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate lossof history. Hence, their use is discouraged.</p>\n","\n","</div>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qN3BIDjWkVgg"},"source":["------------------------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"bQ9M5_NLkVgg"},"source":["Bridge with NumPy {#bridge-to-np-label}\n","=================\n","\n","Tensors on the CPU and NumPy arrays can share their underlying memory\n","locations, and changing one will change the other.\n"]},{"cell_type":"markdown","metadata":{"id":"sYsuayyVkVgg"},"source":["Tensor to NumPy array\n","=====================\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9B_Pw7wPkVgg","executionInfo":{"status":"ok","timestamp":1746536231757,"user_tz":-480,"elapsed":47,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"fffc5c07-3f71-4f5a-cbe6-0d18616fcb45"},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n"]}],"source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")"]},{"cell_type":"markdown","metadata":{"id":"cnr2kjdJkVgh"},"source":["A change in the tensor reflects in the NumPy array.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BPfsuyg3kVgh","executionInfo":{"status":"ok","timestamp":1746536247629,"user_tz":-480,"elapsed":6,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"b974ef8f-f5d4-424d-9f9f-406b95cdc174"},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.])\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["t.add_(1)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]},{"cell_type":"markdown","metadata":{"id":"cHRIWcbQkVgh"},"source":["NumPy array to Tensor\n","=====================\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBuiisbakVgh"},"outputs":[],"source":["n = np.ones(5)\n","t = torch.from_numpy(n)"]},{"cell_type":"markdown","metadata":{"id":"foSPVF6ckVgh"},"source":["Changes in the NumPy array reflects in the tensor.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_WbnEd_kVgh","executionInfo":{"status":"ok","timestamp":1746536304188,"user_tz":-480,"elapsed":9,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"4d53ab36-a716-4d3b-d4e8-7631a2c33a06"},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["np.add(n, 1, out=n)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}