{"cells":[{"cell_type":"markdown","metadata":{"id":"wXxAJFDaf0bk"},"source":["[Learn the Basics](intro.html) \\|\\| **Quickstart** \\|\\|\n","[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n","DataLoaders](data_tutorial.html) \\|\\|\n","[Transforms](transforms_tutorial.html) \\|\\| [Build\n","Model](buildmodel_tutorial.html) \\|\\|\n","[Autograd](autogradqs_tutorial.html) \\|\\|\n","[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n","Model](saveloadrun_tutorial.html)\n","\n","Quickstart\n","==========\n","\n","This section runs through the API for common tasks in machine learning.\n","Refer to the links in each section to dive deeper.\n","\n","Working with data\n","-----------------\n","\n","PyTorch has two [primitives to work with\n","data](https://pytorch.org/docs/stable/data.html):\n","`torch.utils.data.DataLoader` and `torch.utils.data.Dataset`. `Dataset`\n","stores the samples and their corresponding labels, and `DataLoader`\n","wraps an iterable around the `Dataset`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NFTlKrmmf0bm"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor"]},{"cell_type":"markdown","metadata":{"id":"Nr3Qsx0pf0bm"},"source":["PyTorch offers domain-specific libraries such as\n","[TorchText](https://pytorch.org/text/stable/index.html),\n","[TorchVision](https://pytorch.org/vision/stable/index.html), and\n","[TorchAudio](https://pytorch.org/audio/stable/index.html), all of which\n","include datasets. For this tutorial, we will be using a TorchVision\n","dataset.\n","\n","The `torchvision.datasets` module contains `Dataset` objects for many\n","real-world vision data like CIFAR, COCO ([full list\n","here](https://pytorch.org/vision/stable/datasets.html)). In this\n","tutorial, we use the FashionMNIST dataset. Every TorchVision `Dataset`\n","includes two arguments: `transform` and `target_transform` to modify the\n","samples and labels respectively.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ngRsL89Nf0bn","executionInfo":{"status":"ok","timestamp":1746533589810,"user_tz":-480,"elapsed":5313,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"d3694343-2455-4cae-9b6c-f36863402547"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 26.4M/26.4M [00:01<00:00, 16.9MB/s]\n","100%|██████████| 29.5k/29.5k [00:00<00:00, 273kB/s]\n","100%|██████████| 4.42M/4.42M [00:00<00:00, 5.06MB/s]\n","100%|██████████| 5.15k/5.15k [00:00<00:00, 8.61MB/s]\n"]}],"source":["# Download training data from open datasets.\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","# Download test data from open datasets.\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")"]},{"cell_type":"code","source":["training_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8SuM6Hsvg4do","executionInfo":{"status":"ok","timestamp":1746533635572,"user_tz":-480,"elapsed":9,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"7795ba47-5224-4798-89d7-d34e0496693b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset FashionMNIST\n","    Number of datapoints: 60000\n","    Root location: data\n","    Split: Train\n","    StandardTransform\n","Transform: ToTensor()"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"rGBq3jMTf0bn"},"source":["We pass the `Dataset` as an argument to `DataLoader`. This wraps an\n","iterable over our dataset, and supports automatic batching, sampling,\n","shuffling and multiprocess data loading. Here we define a batch size of\n","64, i.e. each element in the dataloader iterable will return a batch of\n","64 features and labels.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqo2_4vBf0bo","executionInfo":{"status":"ok","timestamp":1746533651368,"user_tz":-480,"elapsed":46,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"336e52b7-c6bc-4b2e-b5cf-edc7180186f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n","Shape of y: torch.Size([64]) torch.int64\n"]}],"source":["batch_size = 64\n","\n","# Create data loaders.\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","for X, y in test_dataloader:\n","    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n","    print(f\"Shape of y: {y.shape} {y.dtype}\")\n","    break"]},{"cell_type":"markdown","metadata":{"id":"ERG0vogef0bo"},"source":["Read more about [loading data in PyTorch](data_tutorial.html).\n"]},{"cell_type":"markdown","metadata":{"id":"7QZcHn-pf0bo"},"source":["------------------------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"zwcF9o3Nf0bo"},"source":["Creating Models\n","===============\n","\n","To define a neural network in PyTorch, we create a class that inherits\n","from\n","[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n","We define the layers of the network in the `__init__` function and\n","specify how data will pass through the network in the `forward`\n","function. To accelerate operations in the neural network, we move it to\n","the\n","[accelerator](https://pytorch.org/docs/stable/torch.html#accelerators)\n","such as CUDA, MPS, MTIA, or XPU. If the current accelerator is\n","available, we will use it. Otherwise, we use the CPU.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4z2RGDJf0bp","executionInfo":{"status":"ok","timestamp":1746533775711,"user_tz":-480,"elapsed":14,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"b661d42b-94f5-45e3-8ddc-73a6a41f5211"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}],"source":["device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n","print(f\"Using {device} device\")\n","\n","# Define model\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork().to(device)\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"TCRQ6GsQf0bp"},"source":["Read more about [building neural networks in\n","PyTorch](buildmodel_tutorial.html).\n"]},{"cell_type":"markdown","metadata":{"id":"-czIg0wkf0bp"},"source":["------------------------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"m1LKy3Zvf0bp"},"source":["Optimizing the Model Parameters\n","===============================\n","\n","To train a model, we need a [loss\n","function](https://pytorch.org/docs/stable/nn.html#loss-functions) and an\n","[optimizer](https://pytorch.org/docs/stable/optim.html).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8tr9YTVbf0bp"},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"]},{"cell_type":"markdown","metadata":{"id":"zt67cRbCf0bp"},"source":["In a single training loop, the model makes predictions on the training\n","dataset (fed to it in batches), and backpropagates the prediction error\n","to adjust the model\\'s parameters.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wq6lo-Wrf0bq"},"outputs":[],"source":["def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        # Compute prediction error\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), (batch + 1) * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"]},{"cell_type":"markdown","metadata":{"id":"UB96HR0Zf0bq"},"source":["We also check the model\\'s performance against the test dataset to\n","ensure it is learning.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R3J2bxIFf0bq"},"outputs":[],"source":["def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"]},{"cell_type":"markdown","metadata":{"id":"tWZeGn1Tf0bq"},"source":["The training process is conducted over several iterations (*epochs*).\n","During each epoch, the model learns parameters to make better\n","predictions. We print the model\\'s accuracy and loss at each epoch;\n","we\\'d like to see the accuracy increase and the loss decrease with every\n","epoch.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nj4wUxFHf0bq","executionInfo":{"status":"ok","timestamp":1746534357630,"user_tz":-480,"elapsed":75801,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"fec49220-e92b-4457-ebeb-827ea204ad50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","loss: 2.159397  [   64/60000]\n","loss: 2.150745  [ 6464/60000]\n","loss: 2.092011  [12864/60000]\n","loss: 2.114920  [19264/60000]\n","loss: 2.059308  [25664/60000]\n","loss: 2.000868  [32064/60000]\n","loss: 2.028672  [38464/60000]\n","loss: 1.945779  [44864/60000]\n","loss: 1.955503  [51264/60000]\n","loss: 1.886817  [57664/60000]\n","Test Error: \n"," Accuracy: 54.9%, Avg loss: 1.883086 \n","\n","Epoch 2\n","-------------------------------\n","loss: 1.902498  [   64/60000]\n","loss: 1.883440  [ 6464/60000]\n","loss: 1.766175  [12864/60000]\n","loss: 1.823189  [19264/60000]\n","loss: 1.693929  [25664/60000]\n","loss: 1.656499  [32064/60000]\n","loss: 1.673081  [38464/60000]\n","loss: 1.572583  [44864/60000]\n","loss: 1.605820  [51264/60000]\n","loss: 1.504341  [57664/60000]\n","Test Error: \n"," Accuracy: 59.4%, Avg loss: 1.520467 \n","\n","Epoch 3\n","-------------------------------\n","loss: 1.575401  [   64/60000]\n","loss: 1.551521  [ 6464/60000]\n","loss: 1.401312  [12864/60000]\n","loss: 1.483596  [19264/60000]\n","loss: 1.349079  [25664/60000]\n","loss: 1.362403  [32064/60000]\n","loss: 1.362064  [38464/60000]\n","loss: 1.289738  [44864/60000]\n","loss: 1.331945  [51264/60000]\n","loss: 1.234784  [57664/60000]\n","Test Error: \n"," Accuracy: 62.4%, Avg loss: 1.258328 \n","\n","Epoch 4\n","-------------------------------\n","loss: 1.329823  [   64/60000]\n","loss: 1.316745  [ 6464/60000]\n","loss: 1.150391  [12864/60000]\n","loss: 1.262951  [19264/60000]\n","loss: 1.125918  [25664/60000]\n","loss: 1.169081  [32064/60000]\n","loss: 1.174352  [38464/60000]\n","loss: 1.114296  [44864/60000]\n","loss: 1.160256  [51264/60000]\n","loss: 1.078098  [57664/60000]\n","Test Error: \n"," Accuracy: 64.3%, Avg loss: 1.095307 \n","\n","Epoch 5\n","-------------------------------\n","loss: 1.164320  [   64/60000]\n","loss: 1.168057  [ 6464/60000]\n","loss: 0.984371  [12864/60000]\n","loss: 1.125768  [19264/60000]\n","loss: 0.986075  [25664/60000]\n","loss: 1.036244  [32064/60000]\n","loss: 1.057838  [38464/60000]\n","loss: 1.002493  [44864/60000]\n","loss: 1.046901  [51264/60000]\n","loss: 0.978452  [57664/60000]\n","Test Error: \n"," Accuracy: 65.6%, Avg loss: 0.988903 \n","\n","Done!\n"]}],"source":["epochs = 5\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")"]},{"cell_type":"markdown","metadata":{"id":"rHoUW4QOf0bq"},"source":["Read more about [Training your model](optimization_tutorial.html).\n"]},{"cell_type":"markdown","metadata":{"id":"6kdDK02if0bq"},"source":["------------------------------------------------------------------------\n"]},{"cell_type":"markdown","metadata":{"id":"ZgqU7Izwf0br"},"source":["Saving Models\n","=============\n","\n","A common way to save a model is to serialize the internal state\n","dictionary (containing the model parameters).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gmZvftORf0br","executionInfo":{"status":"ok","timestamp":1746534391857,"user_tz":-480,"elapsed":13,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"49820137-8c15-4f14-aa6a-88fedd1f424f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saved PyTorch Model State to model.pth\n"]}],"source":["torch.save(model.state_dict(), \"model.pth\")\n","print(\"Saved PyTorch Model State to model.pth\")"]},{"cell_type":"markdown","metadata":{"id":"OG_VyMSNf0br"},"source":["Loading Models\n","==============\n","\n","The process for loading a model includes re-creating the model structure\n","and loading the state dictionary into it.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HiAMUnxQf0br","executionInfo":{"status":"ok","timestamp":1746534405660,"user_tz":-480,"elapsed":20,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"a8350b4d-4188-484e-a84d-7e0bfd19819f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":13}],"source":["model = NeuralNetwork().to(device)\n","model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"]},{"cell_type":"markdown","metadata":{"id":"MUmX25Qxf0br"},"source":["This model can now be used to make predictions.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1hErdwZf0br","executionInfo":{"status":"ok","timestamp":1746534414598,"user_tz":-480,"elapsed":6,"user":{"displayName":"Feng Xue","userId":"00196250428882015334"}},"outputId":"b7f1a6f4-79e5-465c-afbd-922899f2dac3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"]}],"source":["classes = [\n","    \"T-shirt/top\",\n","    \"Trouser\",\n","    \"Pullover\",\n","    \"Dress\",\n","    \"Coat\",\n","    \"Sandal\",\n","    \"Shirt\",\n","    \"Sneaker\",\n","    \"Bag\",\n","    \"Ankle boot\",\n","]\n","\n","model.eval()\n","x, y = test_data[0][0], test_data[0][1]\n","with torch.no_grad():\n","    x = x.to(device)\n","    pred = model(x)\n","    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n","    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"]},{"cell_type":"markdown","metadata":{"id":"VUopp9G9f0br"},"source":["Read more about [Saving & Loading your\n","model](saveloadrun_tutorial.html).\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}